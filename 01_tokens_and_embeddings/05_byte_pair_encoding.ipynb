{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2302d58b",
   "metadata": {},
   "source": [
    "# byte-pair encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c298442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23be620e",
   "metadata": {},
   "source": [
    "# initialize the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9130dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' ' appears 7 times.\n",
      "'a' appears 1 times.\n",
      "'e' appears 5 times.\n",
      "'g' appears 5 times.\n",
      "'h' appears 4 times.\n",
      "'i' appears 3 times.\n",
      "'k' appears 2 times.\n",
      "'l' appears 5 times.\n",
      "'n' appears 1 times.\n",
      "'o' appears 2 times.\n",
      "'r' appears 2 times.\n",
      "'s' appears 2 times.\n",
      "'t' appears 1 times.\n",
      "'u' appears 3 times.\n",
      "'v' appears 2 times.\n",
      "'y' appears 1 times.\n"
     ]
    }
   ],
   "source": [
    "# some text with lots of repititions\n",
    "text = \"like liker love lovely hug hugs hugging hearts\"\n",
    "\n",
    "chars = list(set(text))\n",
    "chars.sort() # initial vocab is sorted\n",
    "\n",
    "for l in chars:\n",
    "    print(f\"'{l}' appears {text.count(l)} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c936bce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " 'a': 1,\n",
       " 'e': 2,\n",
       " 'g': 3,\n",
       " 'h': 4,\n",
       " 'i': 5,\n",
       " 'k': 6,\n",
       " 'l': 7,\n",
       " 'n': 8,\n",
       " 'o': 9,\n",
       " 'r': 10,\n",
       " 's': 11,\n",
       " 't': 12,\n",
       " 'u': 13,\n",
       " 'v': 14,\n",
       " 'y': 15}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a vocabulary\n",
    "vocab = {word: i for i, word in enumerate(chars)}\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e946994b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like liker love lovely hug hugs hugging hearts\n",
      "['l', 'i', 'k', 'e', ' ', 'l', 'i', 'k', 'e', 'r', ' ', 'l', 'o', 'v', 'e', ' ', 'l', 'o', 'v', 'e', 'l', 'y', ' ', 'h', 'u', 'g', ' ', 'h', 'u', 'g', 's', ' ', 'h', 'u', 'g', 'g', 'i', 'n', 'g', ' ', 'h', 'e', 'a', 'r', 't', 's']\n"
     ]
    }
   ],
   "source": [
    "# the text needs to be a list, not a string\n",
    "# each element in the list is a token\n",
    "\n",
    "original_text = list(text)\n",
    "print(text)\n",
    "print(original_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458296eb",
   "metadata": {},
   "source": [
    "# find character pairs and merge the most frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4eea4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'li': 2,\n",
       " 'ik': 2,\n",
       " 'ke': 2,\n",
       " 'e ': 2,\n",
       " ' l': 3,\n",
       " 'er': 1,\n",
       " 'r ': 1,\n",
       " 'lo': 2,\n",
       " 'ov': 2,\n",
       " 've': 2,\n",
       " 'el': 1,\n",
       " 'ly': 1,\n",
       " 'y ': 1,\n",
       " ' h': 4,\n",
       " 'hu': 3,\n",
       " 'ug': 3,\n",
       " 'g ': 2,\n",
       " 'gs': 1,\n",
       " 's ': 1,\n",
       " 'gg': 1,\n",
       " 'gi': 1,\n",
       " 'in': 1,\n",
       " 'ng': 1,\n",
       " 'he': 1,\n",
       " 'ea': 1,\n",
       " 'ar': 1,\n",
       " 'rt': 1,\n",
       " 'ts': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_pairs = dict()\n",
    "\n",
    "# loop over tokens\n",
    "for i in range(len(original_text)-1):\n",
    "    # create a pair\n",
    "    pair = original_text[i] + original_text[i+1]\n",
    "\n",
    "    # increase pair frequencies\n",
    "    if pair in token_pairs:\n",
    "        token_pairs[pair] += 1\n",
    "    else:\n",
    "        token_pairs[pair] = 1\n",
    "\n",
    "\n",
    "token_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a6f9568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent character pair is \" h\" with 4 appearances\n"
     ]
    }
   ],
   "source": [
    "# find the most frequent pair\n",
    "most_frequent_pair_idx = np.argmax(list(token_pairs.values()))\n",
    "most_frequent_pair_char = list(token_pairs.keys())[most_frequent_pair_idx]\n",
    "print(f'The most frequent character pair is \"{most_frequent_pair_char}\" with {list(token_pairs.values())[most_frequent_pair_idx]} appearances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffac4288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " 'a': 1,\n",
       " 'e': 2,\n",
       " 'g': 3,\n",
       " 'h': 4,\n",
       " 'i': 5,\n",
       " 'k': 6,\n",
       " 'l': 7,\n",
       " 'n': 8,\n",
       " 'o': 9,\n",
       " 'r': 10,\n",
       " 's': 11,\n",
       " 't': 12,\n",
       " 'u': 13,\n",
       " 'v': 14,\n",
       " 'y': 15,\n",
       " ' h': 16}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update the vocab\n",
    "vocab[most_frequent_pair_char] = max(vocab.values()) + 1\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea54f9d3",
   "metadata": {},
   "source": [
    "# replace the token pair with one token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5260b5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added ' h'\n",
      "added ' h'\n",
      "added ' h'\n",
      "added ' h'\n",
      "\n",
      "\n",
      "Original text: ['l', 'i', 'k', 'e', ' ', 'l', 'i', 'k', 'e', 'r', ' ', 'l', 'o', 'v', 'e', ' ', 'l', 'o', 'v', 'e', 'l', 'y', ' ', 'h', 'u', 'g', ' ', 'h', 'u', 'g', 's', ' ', 'h', 'u', 'g', 'g', 'i', 'n', 'g', ' ', 'h', 'e', 'a', 'r', 't', 's']\n",
      "Updated text: ['l', 'i', 'k', 'e', ' ', 'l', 'i', 'k', 'e', 'r', ' ', 'l', 'o', 'v', 'e', ' ', 'l', 'o', 'v', 'e', 'l', 'y', ' h', 'u', 'g', ' h', 'u', 'g', 's', ' h', 'u', 'g', 'g', 'i', 'n', 'g', ' h', 'e', 'a', 'r', 't']\n",
      "\n",
      "\n",
      "Original text had 46 tokens.\n",
      "\n",
      "\n",
      "New text has 41 tokens.\n"
     ]
    }
   ],
   "source": [
    "# initialize a new text list\n",
    "new_text = []\n",
    "\n",
    "# loop through the list\n",
    "i = 0\n",
    "while i < (len(original_text)-1):\n",
    "    # test whether the pair of this and the following elements match the newly-created pair\n",
    "    if (original_text[i] + original_text[i+1]) == most_frequent_pair_char:\n",
    "        # append to the new version of the text\n",
    "        new_text.append(most_frequent_pair_char)\n",
    "        print(f\"added '{most_frequent_pair_char}'\")\n",
    "        # skip the next character\n",
    "        i += 2\n",
    "    \n",
    "    # this isn't a merged pair, so add this token to list\n",
    "    else:\n",
    "        new_text.append(original_text[i])\n",
    "        # move to the next character\n",
    "        i += 1\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Original text: {original_text}\")\n",
    "print(f\"Updated text: {new_text}\")\n",
    "\n",
    "print(f\"\\n\\nOriginal text had {len(original_text)} tokens.\")\n",
    "print(f\"\\n\\nNew text has {len(new_text)} tokens.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd72c22",
   "metadata": {},
   "source": [
    "# fint the most common letter pairs (again!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2393fcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'li': 2,\n",
       " 'ik': 2,\n",
       " 'ke': 2,\n",
       " 'e ': 2,\n",
       " ' l': 3,\n",
       " 'er': 1,\n",
       " 'r ': 1,\n",
       " 'lo': 2,\n",
       " 'ov': 2,\n",
       " 've': 2,\n",
       " 'el': 1,\n",
       " 'ly': 1,\n",
       " 'y h': 1,\n",
       " ' hu': 3,\n",
       " 'ug': 3,\n",
       " 'g h': 2,\n",
       " 'gs': 1,\n",
       " 's h': 1,\n",
       " 'gg': 1,\n",
       " 'gi': 1,\n",
       " 'in': 1,\n",
       " 'ng': 1,\n",
       " ' he': 1,\n",
       " 'ea': 1,\n",
       " 'ar': 1,\n",
       " 'rt': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_pairs = dict()\n",
    "\n",
    "# loop over the new_text tokens (not the original)\n",
    "for i in range(len(new_text)-1):\n",
    "    # create a pair\n",
    "    pair = new_text[i] + new_text[i+1]\n",
    "\n",
    "    # increase pair frequencies\n",
    "    if pair in token_pairs:\n",
    "        token_pairs[pair] += 1\n",
    "    else:\n",
    "        token_pairs[pair] = 1\n",
    "\n",
    "token_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00bd75d",
   "metadata": {},
   "source": [
    "# now using functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10124f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pair_stats(text2pair):\n",
    "    token_pairs = dict()\n",
    "\n",
    "    # loop over tokens\n",
    "    for i in range(len(text2pair)-1):\n",
    "        # create a pair\n",
    "        pair = text2pair[i] + text2pair[i+1]\n",
    "\n",
    "        # increase pair frequencies\n",
    "        if pair in token_pairs:\n",
    "            token_pairs[pair] += 1\n",
    "        else:\n",
    "            token_pairs[pair] = 1\n",
    "    \n",
    "    return token_pairs\n",
    "\n",
    "\n",
    "def update_vocab(token_pairs, vocab):\n",
    "    # find the most frequent pair\n",
    "    idx = np.argmax(list(token_pairs.values()))\n",
    "    new_token = list(token_pairs.keys())[idx]\n",
    "\n",
    "    # update the vocab\n",
    "    vocab[new_token] = max(vocab.values()) + 1\n",
    "\n",
    "    return vocab, new_token\n",
    "\n",
    "\n",
    "def generate_new_token_sequence(prev_text, new_token):\n",
    "    # initialize a new text list\n",
    "    new_text = []\n",
    "\n",
    "    # loop through the list\n",
    "    i = 0\n",
    "    while i < (len(prev_text)-1):\n",
    "        # test whether the pair of this and the following element match the newly-created pair\n",
    "        if (prev_text[i] + prev_text[i+1]) == new_token:\n",
    "            new_text.append(new_token)\n",
    "            i += 2 # skip the next character\n",
    "        else:\n",
    "            new_text.append(prev_text[i])\n",
    "            i += 1\n",
    "    \n",
    "    if i < len(prev_text):\n",
    "        new_text.append(prev_text[i])\n",
    "\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b06913d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab has 16 tokens.\n"
     ]
    }
   ],
   "source": [
    "# re-initialize the vocab\n",
    "vocab = {word: i for i, word in enumerate(chars)}\n",
    "print(f\"Vocab has {len(vocab)} tokens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a22b021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab has 17 tokens.\n"
     ]
    }
   ],
   "source": [
    "# do one iteration\n",
    "\n",
    "# find and count pairs\n",
    "pairs = get_pair_stats(original_text)\n",
    "\n",
    "# update the dictionary\n",
    "vocab, new_token = update_vocab(pairs, vocab)\n",
    "\n",
    "# get a new list of tokens\n",
    "updated_text = generate_new_token_sequence(original_text, new_token)\n",
    "\n",
    "print(f\"Vocab has {len(vocab)} tokens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54842e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l',\n",
       " 'i',\n",
       " 'k',\n",
       " 'e',\n",
       " ' ',\n",
       " 'l',\n",
       " 'i',\n",
       " 'k',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 'l',\n",
       " 'o',\n",
       " 'v',\n",
       " 'e',\n",
       " ' ',\n",
       " 'l',\n",
       " 'o',\n",
       " 'v',\n",
       " 'e',\n",
       " 'l',\n",
       " 'y',\n",
       " ' h',\n",
       " 'u',\n",
       " 'g',\n",
       " ' h',\n",
       " 'u',\n",
       " 'g',\n",
       " 's',\n",
       " ' h',\n",
       " 'u',\n",
       " 'g',\n",
       " 'g',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' h',\n",
       " 'e',\n",
       " 'a',\n",
       " 'r',\n",
       " 't',\n",
       " 's']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccbeb82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab has 18 tokens.\n"
     ]
    }
   ],
   "source": [
    "## do a second iteration\n",
    "pairs = get_pair_stats(updated_text)\n",
    "\n",
    "# update the dictionary\n",
    "vocab,newtoken = update_vocab(pairs,vocab)\n",
    "\n",
    "# get a new list of tokens\n",
    "updated_text = generate_new_token_sequence(updated_text,newtoken)\n",
    "print(f'Vocab has {len(vocab)} tokens.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37ee123c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l',\n",
       " 'i',\n",
       " 'k',\n",
       " 'e',\n",
       " ' l',\n",
       " 'i',\n",
       " 'k',\n",
       " 'e',\n",
       " 'r',\n",
       " ' l',\n",
       " 'o',\n",
       " 'v',\n",
       " 'e',\n",
       " ' l',\n",
       " 'o',\n",
       " 'v',\n",
       " 'e',\n",
       " 'l',\n",
       " 'y',\n",
       " ' h',\n",
       " 'u',\n",
       " 'g',\n",
       " ' h',\n",
       " 'u',\n",
       " 'g',\n",
       " 's',\n",
       " ' h',\n",
       " 'u',\n",
       " 'g',\n",
       " 'g',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' h',\n",
       " 'e',\n",
       " 'a',\n",
       " 'r',\n",
       " 't',\n",
       " 's']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c8c98d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " 'a': 1,\n",
       " 'e': 2,\n",
       " 'g': 3,\n",
       " 'h': 4,\n",
       " 'i': 5,\n",
       " 'k': 6,\n",
       " 'l': 7,\n",
       " 'n': 8,\n",
       " 'o': 9,\n",
       " 'r': 10,\n",
       " 's': 11,\n",
       " 't': 12,\n",
       " 'u': 13,\n",
       " 'v': 14,\n",
       " 'y': 15,\n",
       " ' h': 16,\n",
       " ' l': 17}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b9e45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-deep-dive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
