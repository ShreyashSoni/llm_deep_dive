{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96af9c57",
   "metadata": {},
   "source": [
    "# Tokenization compression ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba7276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import string\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0afb5278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-4's Tokenizer\n",
    "tokenizer = tiktoken.get_encoding('cl100k_base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bc7f37",
   "metadata": {},
   "source": [
    "# get the books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fac86319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all books have the same url format;\n",
    "# they are unique by numerical code\n",
    "baseurl = 'https://www.gutenberg.org/cache/epub/'\n",
    "\n",
    "bookurls = [\n",
    "    # code       title\n",
    "    ['84',    'Frankenstein'    ],\n",
    "    ['64317', 'GreatGatsby'     ],\n",
    "    ['11',    'AliceWonderland' ],\n",
    "    ['1513',  'RomeoJuliet'     ],\n",
    "    ['76',    'HuckFinn'        ],\n",
    "    ['219',   'HeartDarkness'   ],\n",
    "    ['2591',  'GrimmsTales'     ],\n",
    "    ['2148',  'EdgarAllenPoe'   ],\n",
    "    ['36',    'WarOfTheWorlds'  ],\n",
    "    ['829',   'GulliversTravels']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "627de30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Book title     |  Chars  |  Tokens | Compression\n",
      "--------------------------------------------------\n",
      "Frankenstein     | 446,544 | 102,419 | 22.94%\n",
      "GreatGatsby      | 296,858 |  70,343 | 23.70%\n",
      "AliceWonderland  | 167,674 |  41,457 | 24.72%\n",
      "RomeoJuliet      | 167,429 |  43,761 | 26.14%\n",
      "HuckFinn         | 602,714 | 159,125 | 26.40%\n",
      "HeartDarkness    | 232,885 |  56,483 | 24.25%\n",
      "GrimmsTales      | 549,736 | 137,252 | 24.97%\n",
      "EdgarAllenPoe    | 632,131 | 144,315 | 22.83%\n",
      "WarOfTheWorlds   | 363,420 |  84,580 | 23.27%\n",
      "GulliversTravels | 611,742 | 143,560 | 23.47%\n"
     ]
    }
   ],
   "source": [
    "print('  Book title     |  Chars  |  Tokens | Compression')\n",
    "print('-'*50)\n",
    "\n",
    "for code, title in bookurls:\n",
    "    # get the text\n",
    "    fullurl = baseurl + code + '/pg' + code + '.txt'\n",
    "    text = requests.get(fullurl).text\n",
    "    num_chars = len(text)\n",
    "\n",
    "    # tokenize\n",
    "    tokens = tokenizer.encode(text)\n",
    "    num_tokens = len(tokens)\n",
    "\n",
    "    # compression ratio\n",
    "    compress = (num_tokens / num_chars) * 100\n",
    "\n",
    "    print(f\"{title:16} | {num_chars:>7,d} | {num_tokens:>7,d} | {compress:>3.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658dd378",
   "metadata": {},
   "source": [
    "# let's see some websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8e40c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weburls = [\n",
    "    'http://python.org/',\n",
    "    'https://pytorch.org/',\n",
    "    'https://en.wikipedia.org/wiki/List_of_English_words_containing_Q_not_followed_by_U',\n",
    "    'https://sudoku.com/',\n",
    "    'https://reddit.com/',\n",
    "    'https://visiteurope.com/en/',\n",
    "    'https://sincxpress.com/',\n",
    "    'https://openai.com/',\n",
    "    'https://theuselessweb.com/',\n",
    "    'https://maps.google.com/',\n",
    "    'https://pigeonsarentreal.co.uk/',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5e97165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Website        |  Chars  |  Tokens | Compression\n",
      "-----------------------------------------------------\n",
      "python             |  50,332 |  12,791 |  25.41%\n",
      "pytorch            | 388,061 | 111,398 |  28.71%\n",
      "en.wikipedia       |      92 |      26 |  28.26%\n",
      "sudoku             | 139,673 |  51,094 |  36.58%\n",
      "reddit             | 479,437 | 148,207 |  30.91%\n",
      "visiteurope        | 116,010 |  31,668 |  27.30%\n",
      "sincxpress         |  25,580 |   6,843 |  26.75%\n",
      "openai             |  11,617 |   6,461 |  55.62%\n",
      "theuselessweb      |   4,756 |   1,329 |  27.94%\n",
      "maps.google        | 212,313 | 107,456 |  50.61%\n",
      "pigeonsarentreal.c | 243,854 |  71,232 |  29.21%\n"
     ]
    }
   ],
   "source": [
    "print('    Website        |  Chars  |  Tokens | Compression')\n",
    "print('-'*53)\n",
    "\n",
    "for url in weburls:\n",
    "\n",
    "    # get the text\n",
    "    text = requests.get(url).text\n",
    "    num_chars = len(text)\n",
    "\n",
    "    # tokenize\n",
    "    tokens = tokenizer.encode(text)\n",
    "    num_tokens = len(tokens)\n",
    "\n",
    "    # compression ratio\n",
    "    compress = 100*num_tokens/num_chars\n",
    "\n",
    "    print(f'{urlparse(url).hostname[:-4]:18} | {num_chars:>7,d} | {num_tokens:>7,d} |  {compress:>3.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e451f45f",
   "metadata": {},
   "source": [
    "# using the 'string' library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e16ce9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attribute     |  Chars  |  Tokens | Compression\n",
      "--------------------------------------------------\n",
      "__name__        |       6 |       1 |  16.67%\n",
      "__doc__         |     622 |     109 |  17.52%\n",
      "__package__     |       6 |       1 |  16.67%\n",
      "__file__        |      84 |      22 |  26.19%\n",
      "__cached__      |     109 |      31 |  28.44%\n",
      "whitespace      |       6 |       4 |  66.67%\n",
      "ascii_lowercase |      26 |       1 |   3.85%\n",
      "ascii_uppercase |      26 |       1 |   3.85%\n",
      "ascii_letters   |      52 |       2 |   3.85%\n",
      "digits          |      10 |       4 |  40.00%\n",
      "hexdigits       |      22 |       7 |  31.82%\n",
      "octdigits       |       8 |       3 |  37.50%\n",
      "punctuation     |      32 |      21 |  65.62%\n",
      "printable       |     100 |      31 |  31.00%\n"
     ]
    }
   ],
   "source": [
    "print('  Attribute     |  Chars  |  Tokens | Compression')\n",
    "print('-'*50)\n",
    "\n",
    "for k,v in string.__dict__.items():\n",
    "    if isinstance(v,str) and (len(v)>0):\n",
    "\n",
    "        # get the text\n",
    "        num_chars = len(v)\n",
    "\n",
    "        # tokenize\n",
    "        tokens = tokenizer.encode(v)\n",
    "        num_tokens = len(tokens)\n",
    "\n",
    "        # compression ratio\n",
    "        compress = 100*num_tokens/num_chars\n",
    "\n",
    "        print(f'{k:15} | {num_chars:>7,d} | {num_tokens:>7,d} |  {compress:>5.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee6d9210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A collection of string constants.\\n\\nPublic module variables:\\n\\nwhitespace -- a string containing all ASCII whitespace\\nascii_lowercase -- a string containing all ASCII lowercase letters\\nascii_uppercase -- a string containing all ASCII uppercase letters\\nascii_letters -- a string containing all ASCII letters\\ndigits -- a string containing all ASCII decimal digits\\nhexdigits -- a string containing all ASCII hexadecimal digits\\noctdigits -- a string containing all ASCII octal digits\\npunctuation -- a string containing all ASCII punctuation characters\\nprintable -- a string containing all ASCII characters considered printable\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g.,\n",
    "string.__dict__['__doc__']\n",
    "# string.ascii_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fe9f42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-deep-dive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
